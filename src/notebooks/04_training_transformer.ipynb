{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EYPSsY2wGdWI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "hjyJdsL4GprB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "install"
      ],
      "metadata": {
        "id": "of9ofbKGf1zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers;"
      ],
      "metadata": {
        "id": "u6H5D7hVCbBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb8075f-761d-4589-84d1-a4a68770275f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 79 kB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 16.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 60.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 51.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 10.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 60.6 MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import"
      ],
      "metadata": {
        "id": "pojKz-Fef4mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import svm, neighbors, ensemble, neural_network, linear_model\n",
        "\n",
        "from os.path import exists\n",
        "import os \n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "bqxFJYXu-UIt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "utility functions"
      ],
      "metadata": {
        "id": "hbY1pjybh1GY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_pickle(path):\n",
        "  with open(path, \"rb\") as f:\n",
        "    return pickle.load(f)\n",
        "\n",
        "def write_pickle(path, object):\n",
        "  with open(path, \"wb\") as f:\n",
        "    return pickle.dump(object, f)"
      ],
      "metadata": {
        "id": "RxBJDSpgh4df"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(model_name, dataset_name, column_name, df):\n",
        "  embedding_file_name = f'{column_name}_{dataset_name}_{model_name}.pkl'\n",
        "  embeddings_file_path = os.path.join(embeddings_path, embedding_file_name) \n",
        "  if exists(embeddings_file_path):\n",
        "    print('reading from pickle...')\n",
        "    return read_pickle(embeddings_file_path)\n",
        "  else:\n",
        "    print('calculating...')\n",
        "    model = SentenceTransformer(model_name)\n",
        "    embeddings = model.encode(list(df[column_name].values))\n",
        "    write_pickle(embeddings_file_path, embeddings)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "cMVX8xGRcsec"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "settings"
      ],
      "metadata": {
        "id": "9lBUwqgXg5NF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'nli-mpnet-base-v2'\n",
        "train_dataset = 'train_clean_with_emoticons'\n",
        "validation_dataset = train_dataset.replace('train', 'validation')\n",
        "\n",
        "# use for local\n",
        "#dataset_path = '../datasets'\n",
        "\n",
        "# use for google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset_path = 'drive/MyDrive/siap/datasets' \n",
        "embeddings_path = 'drive/MyDrive/siap/embeddings'\n",
        "assert os.path.isdir(dataset_path)\n",
        "assert os.path.isdir(embeddings_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_wqperiQ4Zn",
        "outputId": "5eda1384-4248-4340-f407-598782395d45"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "read dataset"
      ],
      "metadata": {
        "id": "hrJ-LAVsg7Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(os.path.join(dataset_path, f'{train_dataset}.csv'))\n",
        "df_validation = pd.read_csv(os.path.join(dataset_path, f'{validation_dataset}.csv'))"
      ],
      "metadata": {
        "id": "7espz6Cm_dmg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = df_train.iloc[18000]\n",
        "print(row['Review Text'])\n",
        "print(row['Augmented review text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv96CUpJ6mDd",
        "outputId": "79ae35f7-d18d-4b37-d7b3-8da80fd8d22c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I purchased this dress in the berry color. it is beautiful and feminine. the length fit just like in the picture. i love all the detail and ease of this dress. i'm 5'2\" 34d and purchased a size 2. it fits true to size.\n",
            "The dress was purchased in a berry color. It's feminine and beautiful. The length matches the picture. The dress is easy to wear and I love it. I bought a size 2 because I am 5'2\" 34d. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embed"
      ],
      "metadata": {
        "id": "9FM67a26GYYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = get_embeddings(model_name, train_dataset, 'Review Text', df_train)\n",
        "y_train = df_train['Rating']\n",
        "X_validation = get_embeddings(model_name, validation_dataset, 'Review Text', df_validation)\n",
        "y_validation = df_validation['Rating']"
      ],
      "metadata": {
        "id": "QRF9W8wP_iMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55797da3-b29c-47c4-8e70-b1489d169656"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from pickle...\n",
            "reading from pickle...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Augmented review text' in df_train:\n",
        "    X_train_augmented = get_embeddings(model_name, train_dataset, 'Augmented review text', df_train)\n",
        "    print(X_train.shape)\n",
        "    print(X_train_augmented.shape)\n",
        "    X_train = np.concatenate((X_train, X_train_augmented), axis=0)\n",
        "    y_train = np.concatenate((y_train, y_train), axis=0)\n",
        "    print(X_train.shape)\n",
        "    print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNeTujC3sJiZ",
        "outputId": "7ef00b84-16ab-4835-bead-9e587e3f0fb0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading from pickle...\n",
            "(18113, 768)\n",
            "(18113, 768)\n",
            "(36226, 768)\n",
            "(36226,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "gYVwwfYqGZmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='linear', random_state=1, C=1)\n",
        "#clf = svm.SVC(kernel='rbf', C=0.1, random_state=1)\n",
        "#clf = neighbors.KNeighborsClassifier()\n",
        "#clf = ensemble.RandomForestClassifier(n_estimators=300, max_depth=10)\n",
        "#clf = neural_network.MLPClassifier(random_state=1, early_stopping=True, alpha=0.01, hidden_layer_sizes=[600, 600, 600])\n",
        "#clf = linear_model.LogisticRegressionCV(multi_class='multinomial')\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = clf.predict(X_train)\n",
        "y_validation_pred = clf.predict(X_validation)\n",
        "\n",
        "print('Train >>>', f1_score(y_train, y_train_pred, average='micro'))\n",
        "print('Validation >>>', f1_score(y_validation, y_validation_pred, average='micro'))\n",
        "print('===========================================')"
      ],
      "metadata": {
        "id": "a6WmcfwRA1Hs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64b704c-77b4-4483-baa8-0f1a80a236e8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train >>> 0.7009606360072875\n",
            "Validation >>> 0.6724137931034483\n",
            "===========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "EYPSsY2wGdWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1 score types: \n",
        "\n",
        "1. micro -\n",
        "Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
        "\n",
        "2. macro -\n",
        "Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
        "\n",
        "3. weighted -\n",
        "Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall."
      ],
      "metadata": {
        "id": "yTLb8FSEF9av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training')\n",
        "print(classification_report(y_train, y_train_pred, target_names=['1', '2', '3', '4', '5']))"
      ],
      "metadata": {
        "id": "nkfpjrFlACFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Validation')\n",
        "print(classification_report(y_validation, y_validation_pred, target_names=['1', '2', '3', '4', '5']))"
      ],
      "metadata": {
        "id": "006pXnWCXoyw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}